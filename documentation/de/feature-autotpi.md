# Auto-TPI-Funktion


## Einleitung

Die Funktion **Auto TPI** (oder Selbstlernfunktion) ist eine wichtige Neuerung des Versatile Thermostat. Damit kann der Thermostat seine Regelungskoeffizienten (Kp und Ki) **automatisch** anpassen, indem er das Temperaturverhalten des Raums analysiert.

Im TPI-Modus (Time Proportional & Integral) berechnet der Thermostat einen √ñffnungsprozentsatz oder eine Heizzeit anhand der Abweichung zwischen der Solltemperatur und der Innentemperatur (`Kp`) sowie des Einflusses der Au√üentemperatur (`Ki`).

Die richtigen Koeffizienten (`tpi_coef_int` und `tpi_coef_ext`) zu finden, ist oft komplex und erfordert zahlreiche Versuche. **Das √ºbernimmt Auto TPI.**

## Voraussetzungen

Damit Auto TPI effizient funktioniert:
1.  **Zuverl√§ssiger Temperatursensor**: Der Sensor darf nicht direkt von der W√§rmequelle beeinflusst werden (nicht beim Heizk√∂rper anbringen!).
2.  **Au√üentemperatursensor**: Eine genaue Messung der Au√üentemperatur ist unerl√§sslich.
3.  **TPI-Modus aktiviert**: Diese Funktion ist nur verf√ºgbar, wenn Sie den TPI-Algorithmus verwenden (Thermostat auf Schalter, Ventil oder Klima im TPI-Modus).
4.  **Korrekte Leistungseinstellung**: Stellen Sie die Parameter f√ºr die Aufheizzeit korrekt ein (siehe unten).
5.  **Optimaler Start (wichtig)**: Damit der Lernvorgang effektiv startet, wird empfohlen, ihn zu aktivieren, wenn die Abweichung zwischen der aktuellen Temperatur und dem Sollwert erheblich ist (**2 ¬∞C** sind ausreichend).
*   *Tipp*: K√ºhlen Sie den Raum, aktivieren Sie den Lernvorgang und stellen Sie dann den Komfort-Sollwert wieder ein.

## Konfiguration

Die Konfiguration von Auto TPI ist in den TPI-Konfigurationsablauf f√ºr **jeden einzelnen Thermostat** integriert.

> **Hinweis**: Der Auto-TPI-Lernvorgang kann nicht √ºber die zentrale Konfiguration eingerichtet werden, da jeder Thermostat einen eigenen Lernvorgang ben√∂tigt.

1.  Gehen Sie zur Konfiguration des Versatile Thermostat (**Konfigurieren**).
2.  W√§hlen Sie **TPI-Einstellungen**.
3.  **Wichtig**: Sie m√ºssen die Option **Zentrale TPI-Konfiguration verwenden** deaktivieren, um auf die lokalen Einstellungen zugreifen zu k√∂nnen.
4.  Aktivieren Sie auf dem n√§chsten Bildschirm (TPI-Attribute) ganz unten das **Auto-TPI-Lernen aktivieren**.

Sobald diese Option aktiviert ist, wird ein spezieller Konfigurationsassistent in mehreren Schritten angezeigt:

### Schritt 1: Allgemein

*   **Auto-TPI aktivieren**: Erm√∂glicht das Aktivieren oder Deaktivieren des Lernvorgangs.
*   **Benachrichtigung**: Wenn diese Option aktiviert ist, wird **nur** dann eine Benachrichtigung gesendet, wenn der Lernvorgang als abgeschlossen gilt (50 Zyklen pro Koeffizient).
*   **Konfiguration aktualisieren**: Wenn diese Option aktiviert ist, werden die erlernten TPI-Koeffizienten **automatisch** in der Konfiguration des Thermostats gespeichert, aber **nur wenn der Lernvorgang als abgeschlossen gilt**. Wenn diese Option deaktiviert ist, werden die erlernten Koeffizienten f√ºr die aktuelle TPI-Regelung verwendet, aber nicht in der Konfiguration gespeichert.
* **Kontinuierliches Lernen** (`auto_tpi_continuous_learning`): Wenn diese Option aktiviert ist, wird das Lernen auch nach Abschluss der ersten 50 Zyklen unbegrenzt fortgesetzt. Dadurch kann sich der Thermostat kontinuierlich an allm√§hliche Ver√§nderungen der thermischen Umgebung anpassen (z. B. saisonale Ver√§nderungen, Alterung des Hauses). Wenn diese Option aktiviert ist, werden die gelernten Parameter am Ende jedes Zyklus in der Konfiguration gespeichert (sofern **Konfigurationsaktualisierung** ebenfalls aktiviert ist), sobald das Modell als ‚Äûstabil‚Äù gilt (z. B. nach den ersten 50 Zyklen).
    *   **Fehlerrobustheit**: Im kontinuierlichen Modus stoppen aufeinanderfolgende Fehler das Lernen nicht. Das System ignoriert fehlerhafte Zyklen und setzt seine Anpassung fort.
    *   **Erkennung von Betriebs√§nderungen**: Wenn das kontinuierliche Lernen aktiviert ist, √ºberwacht das System die letzten Lernfehler. Wird eine **systematische Verzerrung** festgestellt (z. B. aufgrund eines Wechsels der Jahreszeit, der Isolierung oder des Heizsystems), wird die Lernrate (Alpha) **vor√ºbergehend erh√∂ht** (auf bis zum Dreifachen des Basiswerts, begrenzt auf 15 %), um die Anpassung zu beschleunigen. Dank dieser Funktion kann sich der Thermostat schnell und ohne manuelles Eingreifen an neue Temperaturbedingungen anpassen.
*   **Externen Koeffizienten beibehalten** (`auto_tpi_keep_ext_learning`): Wenn diese Option aktiviert ist, wird der externe Koeffizient (`Kext`) auch nach Erreichen von 50 Zyklen weiter gelernt, solange der interne Koeffizient (`Kint`) noch nicht stabil ist.
**Hinweis:** Die Beibehaltung der Konfiguration erfolgt nur, wenn beide Koeffizienten stabil sind.
*   **Aufheiz-/Abk√ºhlzeit**: Legen Sie die Tr√§gheit Ihres K√ºhlers fest ([siehe Thermische Konfiguration](#kritische-thermische-konfiguration)).
*   **Obergrenze f√ºr den Innenkoeffizienten**: Sicherheitsgrenzen f√ºr den Innenkoeffizienten (`max 3,0`). **Hinweis**: Bei einer √Ñnderung dieses Grenzwerts im Konfigurationsfluss wird der neue Wert **sofort** auf die gelernten Koeffizienten angewendet, wenn diese √ºber dem neuen Grenzwert liegen (was ein Neuladen der Integration erfordert, was nach dem Speichern einer √Ñnderung √ºber die Optionen der Fall ist).

*   **Heizrate** (`auto_tpi_heating_rate`): Zielwert f√ºr die Temperaturanstiegsrate in ¬∞C/h. ([siehe Konfiguration der Raten](#configuration-des-taux-de-chauffe) )\n*   **Aggressivit√§t** (`auto_tpi_aggressiveness`): Prozentualer Anteil der erlernten W√§rmekapazit√§t, der verwendet werden soll (50-100 %, Standardwert 90 %). Niedrigere Werte f√ºhren zu konservativeren Koeffizienten, wodurch das Risiko einer √úberschreitung des Sollwerts verringert wird.

    *Hinweis: Es ist nicht unbedingt erforderlich, die maximale Heizrate zu verwenden. Je nach Dimensionierung der Heizung k√∂nnen Sie durchaus einen niedrigeren Wert verwenden, **was sogar sehr empfehlenswert ist**.
    Je n√§her Sie an der maximalen Kapazit√§t liegen, desto h√∂her ist der beim Lernen ermittelte Kint-Koeffizient.*

    *Sobald Ihre Kapazit√§t durch den daf√ºr vorgesehenen Dienst definiert oder manuell gesch√§tzt wurde, sollten Sie  einen angemessenen Heizgrad verwenden.
   **Das Wichtigste ist, dass Sie nicht √ºber das hinausgehen, was Ihr Heizk√∂rper in diesem Raum leisten kann.**
    Beispiel: Ihre gemessene adiabatische Kapazit√§t betr√§gt 1,5 ¬∞C/h, 1 ¬∞C/h ist eine Standardkonstante, deren Verwendung sinnvoll ist.*

### Schritt 2: Methode

W√§hlen Sie den Lernalgorithmus:
*   **Durchschnitt (Average)**: Einfacher gewichteter Durchschnitt. Ideal f√ºr schnelles und einmaliges Lernen (leicht zur√ºckzusetzen).
*   **EMA (Exponential Moving Average)**: Exponentieller gleitender Durchschnitt. Sehr empfehlenswert f√ºr kontinuierliches Lernen und Feinabstimmung, da er aktuelle Werte bevorzugt.

### Schritt 3: Verfahrenseinstellungen

Konfigurieren Sie die spezifischen Parameter f√ºr die gew√§hlte Methode:
*   **Durchschnitt**: Anfangsgewichtung.
*   **EMA**: Anfangs-Alpha und Abklingrate (Decay).


### Thermische Konfiguration (kritisch)

Der Algorithmus muss die Reaktionsf√§higkeit Ihres Heizungssystems verstehen.

#### `heater_heating_time` (Thermische Reaktionszeit)
Dies ist die Gesamtzeit, die das System ben√∂tigt, um eine messbare Wirkung auf die Raumtemperatur zu erzielen.

Sie umfasst:
*  Die Aufheizzeit des Heizk√∂rpers (materielle Tr√§gheit).
*  Die Zeit, die die W√§rme ben√∂tigt, um sich im Raum bis zum Sensor auszubreiten.

**Empfohlene Werte:**

| Heizungstyp                                            | Empfohlener Wert |
|--------------------------------------------------------|------------------|
| Elektroheizk√∂rper (Konvektor), Nahsensor               | 2-5 min          |
| Speicherheizung (√ñlbad, Gusseisen), Nahsensor          | 5-10 min         |
| Fu√übodenheizung oder gro√üer Raum mit entferntem Sensor | 10-20 min        |

> Ein falscher Wert kann die Berechnung der Effizienz verf√§lschen und das Lernen verhindern.

#### `heater_cooling_time` (K√ºhlzeit des Heizk√∂rpers)
Zeit, die der Heizk√∂rper ben√∂tigt, um nach dem Ausschalten abzuk√ºhlen. Wird verwendet, um √ºber den `cold_factor` zu sch√§tzen, ob der Heizk√∂rper zu Beginn eines Zyklus ‚Äûwarm‚Äù oder ‚Äûkalt‚Äù ist. Der `cold_factor` erm√∂glicht es, die Tr√§gheit des Heizk√∂rpers zu korrigieren, und dient als **Filter**: Wenn die Aufheizzeit im Vergleich zur gesch√§tzten Aufw√§rmzeit zu kurz ist, wird das Lernen f√ºr diesen Zyklus ignoriert (um St√∂rungen zu vermeiden).

### Automatisches Lernen der W√§rmekapazit√§t ‚ö°

Die W√§rmekapazit√§t (Temperaturanstiegsrate in ¬∞C/h) wird nun w√§hrend des anf√§nglichen Lernvorgangs dank **Bootstrap** **automatisch gelernt**.

#### Wie funktioniert das?

Das System startet mit **aggressiven TPI-Koeffizienten** f√ºr die ersten drei Zyklen, um einen deutlichen Temperaturanstieg zu bewirken und die tats√§chliche Leistung Ihrer Heizung zu messen. Anschlie√üend wechselt es automatisch in den normalen TPI-Modus.

#### Die 2 Startstrategien

1. **Automatikmodus (empfohlen)** ‚úÖ:
   - Lassen Sie `auto_tpi_heating_rate` auf **0** (Standard)
   - Das System erkennt automatisch, dass die Kapazit√§t unbekannt ist
   - Es f√ºhrt 3 Zyklen mit **aggressiven TPI-Koeffizienten** (200,0/5,0) durch, um einen Temperaturanstieg zu bewirken und die Kapazit√§t zu messen
   - **Dies ist der empfohlene Modus f√ºr einen Start ohne Konfiguration**

2. **Manueller Modus**:
   - Setzen Sie `auto_tpi_heating_rate` auf einen bekannten Wert (z. B. 1,5 ¬∞C/h).
   - Der Bootstrap wird vollst√§ndig √ºbersprungen.
   - Das System startet sofort mit dieser Kapazit√§t im TPI-Modus.
   - Verwenden Sie diesen Modus, wenn Sie Ihre Kapazit√§t bereits kennen.

#### Konfiguration

In Schritt 1 der Auto-TPI-Konfiguration:
- **Heizrate** (`auto_tpi_heating_rate`): Lassen Sie den Wert auf **0**, um den automatischen Bootstrap zu aktivieren

> üí° **Tipp**: F√ºr einen optimalen Start des Bootstraps aktivieren Sie das Lernen, wenn die Abweichung zwischen der aktuellen Temperatur und dem Sollwert mindestens 2 ¬∞C betr√§gt.

#### Kalibrierdienst (optional)

Wenn Sie dennoch die Kapazit√§t anhand der Historie sch√§tzen m√∂chten, ohne auf das Bootstrap zu warten:

```yaml
service: versatile_thermostat.auto_tpi_calibrate_capacity
target:
  entity_id: climate.my_thermostat
data:
  save_to_config: true
```

Dieser Dienst analysiert den Verlauf und sch√§tzt die Kapazit√§t, indem er die Momente identifiziert, in denen die Heizung mit voller Leistung l√§uft.

## Funktionsweise

Auto TPI arbeitet zyklisch:

1.  **Beobachtung**: Bei jedem Zyklus (z. B. alle 10 Minuten) misst der Thermostat (der sich im Modus ‚ÄûHEAT‚Äù befindet) die Temperatur zu Beginn und am Ende sowie die verbrauchte Leistung.
2.  **Validierung**: Es wird √ºberpr√ºft, ob der Zyklus f√ºr das Lernen g√ºltig ist:
    *   Das Lernen basiert auf dem Modus `HEAT` des Thermostats, unabh√§ngig vom aktuellen Status des W√§rmesenders (`heating`/`idle`).
    *   Die Leistung war nicht ausgelastet (zwischen 0 % und 100 % ausgeschlossen).
    *   Die Temperaturabweichung ist signifikant.
    *   Das System ist stabil (keine aufeinanderfolgenden Fehler).
    *   Der Zyklus wurde nicht durch eine Leistungsreduzierung (Power Shedding) oder das √ñffnen eines Fensters unterbrochen.
    *   **Fehler erkannt**: Der Lernvorgang wird unterbrochen, wenn eine Anomalie bei der Heizung oder Klimatisierung erkannt wird (z. B. Temperatur steigt trotz Heizung nicht an), um das Einlernen falscher Koeffizienten zu vermeiden.
    * **Zentralheizungskessel**: Wenn der Thermostat von einem Zentralheizungskessel abh√§ngig ist, wird der Lernvorgang unterbrochen, wenn der Kessel nicht aktiviert ist (auch wenn der Thermostat eine Anforderung sendet).
3.  **Berechnung (Lernen)**:
    *   **Fall 1: Interner Koeffizient**. Wenn sich die Temperatur deutlich in die richtige Richtung entwickelt hat (> 0,05 ¬∞C), berechnet er das Verh√§ltnis zwischen der tats√§chlichen Entwicklung **(√ºber den gesamten Zyklus, einschlie√ülich Tr√§gheit)** und der erwarteten theoretischen Entwicklung (korrigiert durch die kalibrierte Kapazit√§t). Es passt `CoeffInt` an, um die Abweichung zu verringern.
    *   **Fall 2: Au√üenkoeffizient**. Wenn das interne Lernen nicht m√∂glich war und die Temperaturabweichung signifikant ist (> 0,1 ¬∞C), passt es `CoeffExt` an, um die Verluste auszugleichen.
        *   **Wichtig**: Das Lernen des Au√üenkoeffizienten wird **blockiert**, wenn die Temperaturabweichung zu gro√ü ist (> 0,5 ¬∞C). Dadurch wird sichergestellt, dass `Kext` (der die Verluste im Gleichgewicht darstellt) nicht durch Probleme mit der Temperaturanstiegsdynamik (die unter `Kint` fallen) verf√§lscht wird.
    *   **Fall 3: Schnelle Korrekturen (Boost/Deboost)**. Parallel dazu √ºberwacht das System kritische Anomalien:
        *   **Boost Kint**: Wenn die Temperatur trotz Heizbedarf stagniert, wird der Innenkoeffizient erh√∂ht. (Optional √ºber `allow_kint_boost_on_stagnation`)
        *   **Deboost Kext**: Wenn die Temperatur den Sollwert √ºberschreitet und nicht wieder sinkt, wird der Au√üenkoeffizient reduziert. (Optional √ºber `allow_kext_compensation_on_overshoot`)
        * Diese Korrekturen werden anhand der Zuverl√§ssigkeit des Modells gewichtet: Je mehr Daten (Lernzyklen) das System hat, desto moderater sind die Korrekturen, um eine Destabilisierung eines zuverl√§ssigen Modells zu vermeiden.*
4.  **Aktualisierung**: Die neuen Koeffizienten werden gegl√§ttet und f√ºr den n√§chsten Zyklus gespeichert.

### Aktivierungssicherheit
Um unbeabsichtigte Aktivierungen zu vermeiden:
1. Der Dienst `set_auto_tpi_mode` lehnt die Aktivierung des Lernmodus ab, wenn "Auto-TPI-Lernmodus aktivieren" in der Konfiguration des Thermostats nicht aktiviert ist.
2. Sollte das Kontrollk√§stchen in der Konfiguration deaktiviert werden, w√§hrend der Lernmodus aktiv war, wird dieser beim Neuladen der Integration automatisch beendet.

## Attribute und Sensoren

Ein spezieller Sensor `sensor.<Thermostatname>_auto_tpi_learning_state` erm√∂glicht die Verfolgung des Lernstatus.

**Verf√ºgbare Attribute:**

*   `active`: Das Lernen ist aktiviert.
*   `heating_cycles_count`: Gesamtzahl der beobachteten Zyklen.
*   `coeff_int_cycles`: Anzahl der Anpassungen des internen Koeffizienten.
*   `coeff_ext_cycles`: Anzahl der Anpassungen des Au√üenkoeffizienten.
*   `model_confidence`: Vertrauensindex (0,0 bis 1,0) f√ºr die Qualit√§t der Einstellungen. Begrenzt auf 100 % nach 50 Zyklen f√ºr jeden Koeffizienten (auch wenn das Lernen fortgesetzt wird).
*   `last_learning_status`: Aktueller Status des Lernvorgangs oder Grund f√ºr das letzte Ergebnis. Lebenszykluswerte: `learning_started` (neues Lernen), `learning_resumed` (Wiederaufnahme nach Pause), `learning_stopped` (unterbrochen). Beispiele f√ºr Lernergebnisse: `learned_indoor_heat`, `power_out_of_range`.
*   `calculated_coef_int` / `calculated_coef_ext`: Aktuelle Werte der Koeffizienten.
*   `learning_start_dt`: Datum und Uhrzeit des Beginns des Lernvorgangs (n√ºtzlich f√ºr Grafiken).
*   `allow_kint_boost_on_stagnation`: Gibt an, ob der Kint-Boost bei Stagnation aktiviert ist.
*   `allow_kext_compensation_on_overshoot`: Gibt an, ob die Kext-Korrektur bei √úberschreitung aktiviert ist.
*   `capacity_heat_status`: Status des Lernens der W√§rmekapazit√§t (`learning` oder `learned`).
*   `capacity_heat_value`: Der Wert der gelernten W√§rmekapazit√§t (in ¬∞C/h).
*   `capacity_heat_count`: Die Anzahl der Bootstrap-Zyklen, die zum Lernen der Kapazit√§t durchgef√ºhrt wurden.

## Services

### Kalibrierungsdienst (`versatile_thermostat.auto_tpi_calibrate_capacity`)

Dieser Dienst erm√∂glicht es, die **adiabatische Kapazit√§t** Ihres Systems (`max_capacity` in ¬∞C/h) durch Analyse der historischen Sensordaten zu sch√§tzen.

**Prinzip:** Der Dienst nutzt den Verlauf der **Sensoren** `temperature_slope` und `power_percent`, um die Zeitpunkte zu ermitteln, zu denen die Heizung mit voller Leistung lief. Er verwendet das **75. Perzentil** (das n√§her an der adiabatischen Temperatur liegt als der Median) und wendet eine **Kext-Korrektur** an: `Capacity = P75 + Kext_config √ó ŒîT`.

```yaml
service: versatile_thermostat.auto_tpi_calibrate_capacity
target:
  entity_id: climate.my_thermostat
data:
  start_date: "2023-11-01T00:00:00+00:00" # Optional. Standardm√§√üig 30 Tage vor "end_date".
  end_date: "2023-12-01T00:00:00+00:00"   # Optional. Standardm√§√üig jetzt.
  min_power_threshold: 95          # Optional. Seuil de puissance en % (0-100). D√©faut 95.
  capacity_safety_margin: 20       # Optional. Sicherheitsmarge in % (0-100), die von der berechneten Kapazit√§t abgezogen werden soll. Standardwert 20.
  save_to_config: true             # Optional. Die empfohlene Kapazit√§t (nach Marge) in der Konfiguration speichern. Standardwert false.
```

> **Ergebnis**: Der Wert der adiabatischen Kapazit√§t (`max_capacity_heat`) wird in den Attributen des Lernzustandssensors mit dem **empfohlenen Wert** (berechnete Kapazit√§t ‚Äì Sicherheitsmarge) aktualisiert.
>
> Der Dienst gibt au√üerdem die folgenden Informationen zur√ºck, um die Qualit√§t der Kalibrierung zu analysieren:
> *   **`max_capacity`**: Die gesch√§tzte adiabatische Bruttokapazit√§t (in ¬∞C/h).
> *   **`recommended_capacity`**: Die empfohlene Kapazit√§t nach Anwendung der Sicherheitsmarge (in ¬∞C/h). Dieser Wert wird gespeichert.
> *   **`margin_percent`**: Die angewandte Sicherheitsmarge (in %).
> *   **`observed_capacity`**: Das 75. Perzentil brutto (vor Kext-Korrektur).
> *   **`kext_compensation`**: Der angewandte Korrekturwert (Kext √ó ŒîT).
> *   **`avg_delta_t`**: Der f√ºr die Korrektur verwendete durchschnittliche ŒîT-Wert.
> *   **`reliability`**: Zuverl√§ssigkeitsindex (in %) basierend auf der Anzahl der Stichproben und der Varianz.
> *   **`samples_used`**: Anzahl der nach der Filterung verwendeten Stichproben.
> *   **`outliers_removed`**: Anzahl der entfernten Ausrei√üer.
> *   **`min_power_threshold`**: Verwendeter Leistungsschwellenwert.
> *   **`period`**: Anzahl der analysierten Tage im Verlauf.
>
> Die TPI-Koeffizienten (`Kint`/`Kext`) werden dann durch die normale Lernschleife unter Verwendung dieser F√§higkeit als Referenz gelernt oder angepasst.

### Lernen aktivieren/deaktivieren (`versatile_thermostat.set_auto_tpi_mode`)

Mit diesem Service kann das Auto-TPI-Lernen ohne Konfiguration des Thermostats gesteuert werden.

#### Parameter

| Parameter                              | Typ     | Standard | Beschreibung                                              |
|----------------------------------------|---------|----------|-----------------------------------------------------------|
| `auto_tpi_mode`                        | boolean | -        | Aktiviert (`true`) oder deaktiviert (`false`)  das Lernen |
| `reinitialise`                         | boolean | `true`   | Steuert das Zur√ºcksetzen der Daten bei Aktivierung        |
| `allow_kint_boost_on_stagnation`       | boolean | `false`  | Erlaubt den Boost von Kint bei Temperaturstagnation       |
| `allow_kext_compensation_on_overshoot` | boolean | `false`  | Erlaubt Kext-Ausgleich bei √úberschreitung (Overshoot)     |

#### Verhalten des Parameters `reinitialise`

Der Parameter `reinitialise` bestimmt, wie vorhandene Trainingsdaten bei der Aktivierung behandelt werden:

- **`reinitialise: true`** (Standard): L√∂scht alle Lerndaten (Koeffizienten und Z√§hler) und beginnt den Lernvorgang von vorne. Die kalibrierten Kapazit√§ten (`max_capacity_heat`/`cool`) bleiben erhalten.
- **`reinitialise: false`**: Setzt das Lernen mit den vorhandenen Daten fort, ohne diese zu l√∂schen. Die vorherigen Koeffizienten und Z√§hler bleiben erhalten und das Lernen wird anhand dieser Werte fortgesetzt.

**Anwendungsfall:** Erm√∂glicht es, das Lernen vor√ºbergehend zu deaktivieren (z. B. w√§hrend einer Urlaubszeit oder bei Bauarbeiten) und es anschlie√üend wieder zu aktivieren, ohne die bereits erzielten Fortschritte zu verlieren.

#### Beispiele

**Neuen Lernvorgang starten (vollst√§ndiges Zur√ºcksetzen):**
```yaml
service: versatile_thermostat.set_auto_tpi_mode
target:
  entity_id: climate.mon_thermostat
data:
  auto_tpi_mode: true
  reinitialise: true  # oder weggelassen, weil das der Fehler ist.
```

**Das Lernen fortsetzen, ohne Daten zu verlieren:**
```yaml
service: versatile_thermostat.set_auto_tpi_mode
target:
  entity_id: climate.mon_thermostat
data:
  auto_tpi_mode: true
  reinitialise: false
```

**Das Lernen beenden:**

Wenn die Lernphase beendet ist:

- Das Lernen ist **deaktiviert**, aber die gelernten Daten bleiben in den Attributen der Entit√§t **auto_tpi_learning_state** **sichtbar**.
- Die Regelung verwendet die **Konfigurationskoeffizienten** (nicht die gelernten Koeffizienten).


## Berechnungsmethode Gewichteter Durchschnitt

La m√©thode **Moyenne Pond√©r√©e** (Average) est une approche simple et efficace pour l'apprentissage des coefficients TPI. Elle est particuli√®rement adapt√©e pour un apprentissage rapide et unique, ou lorsque vous souhaitez r√©initialiser facilement les coefficients.

### Verhalten

La m√©thode Moyenne Pond√©r√©e calcule une moyenne pond√©r√©e entre les coefficients existants et les nouvelles valeurs calcul√©es. Comme la m√©thode EMA, elle r√©duit progressivement l'influence des nouveaux cycles au fur et √† mesure de l'apprentissage, mais utilise une approche diff√©rente.

**Caract√©ristique cl√©** : Plus le nombre de cycles augmente, plus le poids du coefficient existant devient important par rapport au nouveau coefficient. Cela signifie que l'influence des nouveaux cycles diminue progressivement au fur et √† mesure de l'apprentissage.

### Parameter

| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| **Poids initial** (`avg_initial_weight`) | Poids initial donn√© aux coefficients de configuration au d√©marrage | 1 |

### Formel

```
avg_coeff = ((old_coeff √ó weight_old) + coeff_new) / (weight_old + 1)
```

O√π :
- `old_coeff` est le coefficient actuel
- `coeff_new` est le nouveau coefficient calcul√© pour ce cycle
- `weight_old` est le nombre de cycles d'apprentissage d√©j√† effectu√©s (avec un minimum de 1)

**Exemple d'√©volution du poids** :
- Cycle 1 : weight_old = 1 ‚Üí nouveau coefficient a un poids de 50%
- Cycle 10 : weight_old = 10 ‚Üí nouveau coefficient a un poids de ~9%
- Cycle 50 : weight_old = 50 ‚Üí nouveau coefficient a un poids de ~2%
- Cycle 100+ : weight_old = 50 (plafonn√©) ‚Üí nouveau coefficient a encore un poids ~2% pour assurer la r√©activit√©

### Hauptmerkmale

1. **Simplicit√©** : La m√©thode est facile √† comprendre
2. **R√©initialisation facile** : Les coefficients peuvent √™tre facilement r√©initialis√©s en red√©marrant l'apprentissage
3. **Apprentissage progressif** : L'influence des nouveaux cycles diminue au fur et √† mesure, stabilisant progressivement les coefficients
4. **Convergence rapide** : La m√©thode atteint une stabilit√© apr√®s environ 50 cycles

### Vergleich mit EMA

| Aspect | Moyenne Pond√©r√©e | EMA |
|--------|------------------|-----|
| **Complexit√©** | Simple | Plus complexe |
| **M√©canisme de r√©duction** | Poids bas√© sur le nombre de cycles | Alpha adaptatif avec d√©croissance |
| **Stabilit√©** | Stable apr√®s 50 cycles | Stable apr√®s 50 cycles avec d√©croissance alpha |
| **Adaptation continue** | Moins adapt√©e | Plus adapt√©e (meilleure pour les changements progressifs) |
| **R√©initialisation** | Tr√®s facile | Facile |

### Nutzungsempfehlungen

- **Apprentissage initial** : La m√©thode Moyenne Pond√©r√©e est excellente pour un premier apprentissage rapide
- **R√©glages ponctuels** : Id√©ale lorsque vous souhaitez ajuster les coefficients une seule fois
- **Environnements stables** : Bien adapt√©e aux environnements thermiques relativement stables

### Beispiel f√ºr Lernfortschritte

| Cycle | Poids ancien | Poids nouveau | Nouveau coefficient | R√©sultat |
|-------|--------------|---------------|---------------------|----------|
| 1 | 1 | 1 | 0.15 | (0.10 √ó 1 + 0.15 √ó 1) / 2 = 0.125 |
| 2 | 2 | 1 | 0.18 | (0.125 √ó 2 + 0.18 √ó 1) / 3 = 0.142 |
| 10 | 10 | 1 | 0.20 | (0.175 √ó 10 + 0.20 √ó 1) / 11 = 0.177 |
| 50 | 50 | 1 | 0.19 | (0.185 √ó 50 + 0.19 √ó 1) / 51 = 0.185 |

**Note** : Apr√®s 50 cycles, le coefficient est consid√©r√© comme stable et l'apprentissage s'arr√™te (sauf si l'apprentissage continu est activ√©). √Ä ce stade, le nouveau coefficient n'a plus qu'un poids d'environ 2% dans la moyenne.

## Adaptive EMA-Berechnungsmethode

La m√©thode EMA (Exponential Moving Average) utilise un coefficient **alpha** qui d√©termine
l'influence de chaque nouveau cycle sur les coefficients appris.

### Verhalten

Au fil des cycles, **alpha d√©cro√Æt progressivement** pour stabiliser l'apprentissage :

| Cycles | Alpha (avec Œ±‚ÇÄ=0.2, k=0.1) | Influence du nouveau cycle |
|--------|----------------------------|---------------------------|
| 0 | 0.20 | 20% |
| 10 | 0.10 | 10% |
| 50 | 0.033 | 3.3% |
| 100 | 0.033 | 3.3% (plafonn√© √† 50 cycles) |

### Parameter

| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| **Alpha initial** (`ema_alpha`) | Influence au d√©marrage | 0.2 (20%) |
| **Taux de d√©croissance** (`ema_decay_rate`) | Vitesse de stabilisation | 0.1 |

### Formel

```
alpha(n) = alpha_initial / (1 + decay_rate √ó n)
```

O√π `n` est le nombre de cycles d'apprentissage (plafonn√© √† 50).

### Sonderf√§lle

- **decay_rate = 0** : Alpha reste fixe (comportement EMA classique)
- **decay_rate = 1, alpha = 1** : √âquivalent √† la m√©thode "Moyenne Pond√©r√©e"

### Empfehlungen

| Situation | Alpha (`ema_alpha`) | Taux de D√©croissance (`ema_decay_rate`) |
|---|---|---|
| **Apprentissage initial** | `0.15` | `0.08` |
| **Apprentissage fin** | `0.08` | `0.12` |
| **Apprentissage continu** | `0.05` | `0.02` |

**Explications:**

- **Apprentissage initial:**

  *Alpha:* 0.15 (15% de poids initial)

  *Avec ces param√®tres, le syst√®me garde en t√™te principalement les 20 derniers cycles*

  * Cycle 1: Œ± = 0.15 (forte r√©activit√© initiale)
  * Cycle 10: Œ± = 0.083 (commence √† stabiliser)
  * Cycle 25: Œ± = 0.050 (filtrage accru)
  * Cycle 50: Œ± = 0.036 (robustesse finale)


  *Taux de d√©croissance:* 0.08

  D√©croissance mod√©r√©e permettant une adaptation rapide aux 10 premiers cycles
  Balance optimale entre vitesse (√©viter stagnation) et stabilit√© (√©viter sur-ajustement)

- **Apprentissage fin**

  *Alpha:* 0.08 (8% de  poids initial)

  *Avec ces param√®tres, le syst√®me garde en t√™te principalement les 50 derniers cycles*

  D√©marrage conservateur (coefficients d√©j√† bons)
  √âvite les sur-corrections brutales

  * Cycle 1 : Œ± = 0.08
  * Cycle 25 : Œ± = 0.024
  * Cycle 50+ : Œ± = 0.013 (plafonn√©)


  *Taux de d√©croissance:*: 0.12

  D√©croissance plus rapide que l'apprentissage initial
  Converge vers un filtrage tr√®s fort (stabilit√©)
  Adaptation majoritaire dans les 15 premiers cycles

- **Apprentissage continu**
  
  *Alpha* = 0.05 (5% de poids initial)

  *Avec ces param√®tres, le syst√®me garde en t√™te principalement les 100 derniers cycles*

  Tr√®s conservateur pour √©viter d√©rive
  R√©activit√© mod√©r√©e aux changements graduels

  * Cycle 1 : Œ± = 0.05
  * Cycle 50 : Œ± = 0.025
  * Cycle 100+ : Œ± = 0.025 (plafonn√©)


  *Taux de d√©croissance:* = 0.02

  D√©croissance tr√®s lente (apprentissage √† long terme)
  Maintient une capacit√© d'adaptation m√™me apr√®s des centaines de cycles
  Adapt√© aux variations saisonni√®res (hiver/√©t√©)